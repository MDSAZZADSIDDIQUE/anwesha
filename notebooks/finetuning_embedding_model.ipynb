{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to parse the PDF: ../data/raw/HSC26-Bangla1st-Paper.pdf...\n",
      "Started parsing the file under job_id 016f7b0c-2f9e-4703-85de-7d36de57ccf0\n",
      "PDF parsing completed successfully.\n",
      "Chunking documents...\n",
      "Created 226 text chunks.\n",
      "Generating synthetic dataset for fine-tuning...\n",
      "Generated 10/217 examples...\n",
      "Generated 20/217 examples...\n",
      "Generated 30/217 examples...\n",
      "Generated 40/217 examples...\n",
      "Generated 50/217 examples...\n",
      "Generated 60/217 examples...\n",
      "Generated 70/217 examples...\n",
      "Generated 80/217 examples...\n",
      "Generated 90/217 examples...\n",
      "Generated 100/217 examples...\n",
      "Generated 110/217 examples...\n",
      "Generated 120/217 examples...\n",
      "Generated 130/217 examples...\n",
      "Generated 140/217 examples...\n",
      "Generated 150/217 examples...\n",
      "Generated 160/217 examples...\n",
      "Generated 170/217 examples...\n",
      "Generated 180/217 examples...\n",
      "Generated 190/217 examples...\n",
      "Generated 200/217 examples...\n",
      "Generated 210/217 examples...\n",
      "Successfully generated 217 training examples.\n",
      "\n",
      "--- Starting Model Fine-Tuning ---\n",
      "Loading base model: intfloat/multilingual-e5-large-instruct\n",
      "Training parameters: epochs=2, batch_size=16, warmup_steps=2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dfd473d65549b780097b98801c987e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.85 GiB is allocated by PyTorch, and 68.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 295\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCosine Similarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 258\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    255\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=\u001b[32m2e-5\u001b[39m)\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# Start the training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfine_tuned_model_output_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_save_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save a checkpoint every 100 steps\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfine_tuned_model_output_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/checkpoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    268\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    271\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Fine-tuning complete. Model saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfine_tuned_model_output_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# --- 7. Demonstrate Usage of the Fine-Tuned Model ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\sentence_transformers\\fit_mixin.py:408\u001b[39m, in \u001b[36mFitMixin.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[39m\n\u001b[32m    405\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCheckpoint directory does not exist or is not a directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m         resume_from_checkpoint = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\transformers\\trainer.py:2206\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2204\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\transformers\\trainer.py:2607\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2603\u001b[39m         grad_norm = _grad_norm\n\u001b[32m   2605\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2607\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2609\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2611\u001b[39m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\accelerate\\optimizer.py:179\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    177\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m opt = opt_ref()\n\u001b[32m    123\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mdsaz\\Artificial Intelligence\\anwesha\\venv\\Lib\\site-packages\\torch\\optim\\adam.py:757\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    755\u001b[39m     exp_avg_sq_sqrt = torch._foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     exp_avg_sq_sqrt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[32m    760\u001b[39m torch._foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 9.85 GiB is allocated by PyTorch, and 68.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fine-Tuning Script for Multilingual-E5-Large-Instruct Model.\n",
    "\n",
    "This script provides a complete workflow to fine-tune the\n",
    "'intfloat/multilingual-e5-large-instruct' embedding model on a custom dataset\n",
    "generated from a single PDF document.\n",
    "\n",
    "The process involves:\n",
    "1.  Setting up the environment and API keys.\n",
    "2.  Parsing the PDF document to extract text.\n",
    "3.  Cleaning and preprocessing the extracted text.\n",
    "4.  Splitting the text into manageable chunks.\n",
    "5.  Synthetically generating a question-answer dataset from the text chunks using a generator LLM.\n",
    "6.  Configuring the fine-tuning process using the sentence-transformers library.\n",
    "7.  Running the training and saving the fine-tuned model.\n",
    "8.  Demonstrating how to load and use the newly fine-tuned model.\n",
    "\n",
    "Prerequisites:\n",
    "- Install all required libraries:\n",
    "  pip install sentence-transformers torch datasets llama_parse langchain langchain-groq python-dotenv rank_bm25\n",
    "- A LlamaParse API key for parsing the document.\n",
    "- A Groq API key for the generator model.\n",
    "- Place these keys in a .env file in the same directory.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_cloud_services import LlamaParse\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# --- 1. Environment Setup ---\n",
    "# Load API keys and environment variables from a .env file\n",
    "\n",
    "# Check for necessary API keys\n",
    "# LLAMA_CLOUD_API_KEY = userdata.get(\"LLAMA_CLOUD_API_KEY\")\n",
    "# GROQ_API_KEY = userdata.get(\"GROQ_API_KEY\")\n",
    "\n",
    "# if not LLAMA_CLOUD_API_KEY or not GROQ_API_KEY:\n",
    "#     raise ValueError(\n",
    "#         \"API keys for LlamaParse (LLAMA_CLOUD_API_KEY) and Groq (GROQ_API_KEY) are required. \"\n",
    "#         \"Please add them to your .env file.\"\n",
    "#     )\n",
    "\n",
    "# --- 2. PDF Parsing and Text Extraction ---\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def parse_pdf(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Parses a PDF file using LlamaParse and returns the content as LangChain documents.\n",
    "    \"\"\"\n",
    "    print(f\"Starting to parse the PDF: {file_path}...\")\n",
    "    parser = LlamaParse(\n",
    "        result_type=\"markdown\",\n",
    "        use_vendor_multimodal_model=True,\n",
    "        vendor_multimodal_model_name=\"anthropic-sonnet-4.0\",\n",
    "        verbose=True,\n",
    "        language=\"bn\"\n",
    "    )\n",
    "    try:\n",
    "        llama_parse_documents = parser.load_data(file_path)\n",
    "        print(\"PDF parsing completed successfully.\")\n",
    "        return [Document(page_content=doc.text) for doc in llama_parse_documents]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during PDF parsing: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def clean_raw_markdown(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans raw markdown text by removing boilerplate, correcting OCR errors,\n",
    "    and normalizing whitespace. This function is adapted from your notebook.\n",
    "    \"\"\"\n",
    "    boilerplate_patterns = [\n",
    "        re.compile(p, flags=re.MULTILINE | re.IGNORECASE) for p in [\n",
    "            r\"HSC\\s?'?26\\s+অনলাইন\\s+(?:ব্যাচ|গাইড|স্কুল|ক্যাট)\",\n",
    "            r\"বাংলা\\s*[•-]\\s*ইংরেজি\\s*[•-]\\s*(?:আইসিটি|গণিত|তথ্য\\s+ও\\s+যোগাযোগ(?: প্রযুক্তি)?)\",\n",
    "            r'10\\s*MINUTE\\s*SCHOOL',\n",
    "            r'---',\n",
    "            r'^\\d+$',\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    text = raw_text\n",
    "    for pattern in boilerplate_patterns:\n",
    "        text = pattern.sub('', text)\n",
    "\n",
    "    correction_map = {\n",
    "        'কন্যাগী': 'কল্যাণী', 'শত্রুনাশ': 'শম্ভুনাথ', 'শুভনাথ': 'শম্ভুনাথ',\n",
    "        'গুনের': 'গুণের', 'রুপ': 'রূপ', 'বিদ্রোপ': 'বিদ্রূপ', 'কাহিনী': 'কাহিনি',\n",
    "        'বাড়ী': 'বাড়ি', 'গাড়ী': 'গাড়ি', 'শাড়ী': 'শাড়ি',\n",
    "    }\n",
    "    for wrong, right in correction_map.items():\n",
    "        text = text.replace(wrong, right)\n",
    "\n",
    "    text = re.sub(r'(\\w)-\\n(\\w)', r'\\1\\2', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    text = '\\n'.join([line.strip() for line in text.split('\\n')])\n",
    "\n",
    "    return unicodedata.normalize('NFC', text).strip()\n",
    "\n",
    "\n",
    "def chunk_documents(documents: List[Document]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Splits a list of documents into smaller text chunks.\n",
    "    \"\"\"\n",
    "    print(\"Chunking documents...\")\n",
    "    full_text = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    cleaned_text = clean_raw_markdown(full_text)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"।\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = text_splitter.split_text(cleaned_text)\n",
    "    print(f\"Created {len(chunks)} text chunks.\")\n",
    "    return [chunk for chunk in chunks if len(chunk.strip()) > 100]\n",
    "\n",
    "\n",
    "def generate_finetuning_dataset(chunks: List[str]) -> List[InputExample]:\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for fine-tuning by creating question-passage pairs.\n",
    "    It uses a generator model to create a question for each text chunk.\n",
    "    \"\"\"\n",
    "    print(\"Generating synthetic dataset for fine-tuning...\")\n",
    "    generator_llm = ChatGroq(model_name=\"moonshotai/kimi-k2-instruct\")\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Based on the following text passage from a story, please generate one precise and relevant question that can be answered directly from the text.\n",
    "    The question should be in Bengali.\n",
    "\n",
    "    Text Passage:\n",
    "    ---\n",
    "    {passage}\n",
    "    ---\n",
    "\n",
    "    Generated Question:\n",
    "    \"\"\"\n",
    "\n",
    "    training_examples = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            full_prompt = prompt_template.format(passage=chunk)\n",
    "            question = generator_llm.invoke(full_prompt).content\n",
    "\n",
    "            example = InputExample(texts=[question, chunk])\n",
    "            training_examples.append(example)\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Generated {i + 1}/{len(chunks)} examples...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Skipping a chunk due to an error during question generation: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\n",
    "        f\"Successfully generated {len(training_examples)} training examples.\")\n",
    "    return training_examples\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the end-to-end fine-tuning process.\n",
    "    \"\"\"\n",
    "    pdf_file_path = \"../data/raw/HSC26-Bangla1st-Paper.pdf\"\n",
    "    base_model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "    fine_tuned_model_output_path = \"../models\"\n",
    "\n",
    "    num_epochs = 2\n",
    "    batch_size = 16\n",
    "\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"Error: The file '{pdf_file_path}' was not found.\")\n",
    "        print(\"Please make sure the PDF is in the same directory as this script.\")\n",
    "        return\n",
    "\n",
    "    documents = parse_pdf(pdf_file_path)\n",
    "    if not documents:\n",
    "        print(\"Could not extract any documents from the PDF. Exiting.\")\n",
    "        return\n",
    "\n",
    "    text_chunks = chunk_documents(documents)\n",
    "    if not text_chunks:\n",
    "        print(\"No text chunks were created. Exiting.\")\n",
    "        return\n",
    "\n",
    "    training_dataset = generate_finetuning_dataset(text_chunks)\n",
    "    if not training_dataset:\n",
    "        print(\"Failed to generate a training dataset. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Starting Model Fine-Tuning ---\")\n",
    "\n",
    "    print(f\"Loading base model: {base_model_name}\")\n",
    "    model = SentenceTransformer(base_model_name)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "    # Calculate warmup steps\n",
    "    warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "    print(\n",
    "        f\"Training parameters: epochs={num_epochs}, batch_size={batch_size}, warmup_steps={warmup_steps}\")\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        optimizer_class=type(optimizer),\n",
    "        optimizer_params={'lr': 2e-5},\n",
    "        output_path=fine_tuned_model_output_path,\n",
    "        show_progress_bar=True,\n",
    "        checkpoint_save_steps=100,\n",
    "        checkpoint_path=f\"{fine_tuned_model_output_path}/checkpoints\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"--- Fine-tuning complete. Model saved to: {fine_tuned_model_output_path} ---\")\n",
    "\n",
    "    print(\"\\n--- Testing the Fine-Tuned Model ---\")\n",
    "    fine_tuned_model = SentenceTransformer(fine_tuned_model_output_path)\n",
    "\n",
    "    test_query = \"বিবাহ অনুষ্ঠানে মামার আচরণ কেমন ছিল?\"\n",
    "    test_passage = \"মামা বিবাহ-বাড়িতে ঢুকিয়া খুশি হইলেন না। একে তো উঠানটাতে বরযাত্রীদের জায়গা সংকুলান হওয়াই শক্ত, তাহার পরে সমস্ত আয়োজন নিতান্ত মধ্যম রকমের।\"\n",
    "\n",
    "    query_embedding = fine_tuned_model.encode(\n",
    "        test_query, convert_to_tensor=True)\n",
    "    passage_embedding = fine_tuned_model.encode(\n",
    "        test_passage, convert_to_tensor=True)\n",
    "\n",
    "    similarity = torch.nn.functional.cosine_similarity(\n",
    "        query_embedding, passage_embedding, dim=0)\n",
    "\n",
    "    print(f\"Test Query: {test_query}\")\n",
    "    print(f\"Test Passage: {test_passage}\")\n",
    "    print(f\"Cosine Similarity: {similarity.item():.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
